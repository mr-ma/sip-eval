```sip-eval``` project contains dataset of programs and a number of scripts to evaluate OH+SROH and SC protection on a given dataset. There are two directories containing dataset bitcodes. ```coverage_dataset``` contains bitcodes for which OH+SROH coverage measurements are done. ```protection_dataset``` contains bitcodes on which full protection is applied, i.e. OH+SROH+SC.
With the scripts following information can be generated

	- Input dependency coverage results
 	- OH+SROH protection coverage results for instructions and basic blocks
	- The coverage table in the paper
	- Performance overheads
	- OH+SROH+SC time to protect (protection process) 
	- Generate protected binaries
	- Protected binaries runtime
	
Docker container
--------------------------------------------------
Build a docker image using the provided [DockerFile](https://github.com/tum-i22/sip-oblivious-hashing/tree/acsac/docker).
Run docker container with the following parameters:
```docker run -v /sys/fs/cgroup:/sys/fs/cgroup:rw --security-opt seccomp=unconfined {IMAGEID/IMAGENAME}```

Input dependency coverage results
----------------------------------
To get input dependency analysis results as a tex table run ```generate-dataset-coverage-tables.sh``` script which internally runs following scripts

	./dataset_info.sh
	python dataset_info.py
	python tables_dump.py

The first script runs OH+SROH on bitcodes in ```coverage_dataset``` directory. This assumes also running input dependency analysis on those bitcodes. ```dataset_info.py``` parses statistics files generated by the previous script and creates json files out of them. It outputs three json files - ```coverage.json, dataset_info.json, paper_table.json```. Running ```tables_dump``` will generate tex tables from data in those json files. The json files are committed and one can just run ```tables_dump.py``` to generate tables. Generated tables are ```dataset_tables.tex``` which contains input dependency coverage data. Two other tables are generated by this script - ```paper_table.tex``` and ```coverage_table.tex```. All tablesa are placed in tex directory.


OH+SROH protection coverage results for instructions and basic blocks
---------------------------------------------------------------------
To generate OH+SROH protection coverage results run the same commands as for the input dependency coverage results. OH+SROH coverage results are in ```dataset_tables.tex``` as two separate tables for instruction coverage information and basic block coverage information. ```coverage_table.tex``` also contains coverage data combined into one tables. 

The coverage table in the paper
---------------------------------------
```paper_table.tex``` generated by ```generate-dataset-coverage-tables.sh``` contains the table from the paper.

Performance overheads
---------------------------------------
To measure the overhead of the protection, all you need to run is ``run-all.sh`` (in the root of the repository).
This script transforms all the programs that are placed in the `protection_dataset` directory. 
It undertakes a set of steps seqeuentially: 
- optimize bcs (`coverage-improver.sh`)
- create random function combinations for different coverage levels, namely 10, 25, 50 , and 100% (`combinator.sh`)
	- The defualt number of combinations is set to 20, you may change this value by setting `num_combination=20` to your desired number of combinations.
- generate protected binaries (`generator.sh` for OH+SROh+SC and `generator-sc.sh` for SC protection only)
- run unprotected (baseline) and protected binaries and record elapsed times (`runexec-binaries.sh`) 
- measure overheads (`measure.py`)
- dump the stacked overhead graph (`plot-dump-combined.py`)

The generated graph is stored in the root of the repository as `performance-evaluation-combined-percentage.pdf`.
Detailed report of overheads can be found under `binaries/measurements.json` (for OH+SROH+SC) and `binaries-sc/measurements.json` (for SC). 

OH+SROH+SC time to protect (protection process) 
--------------------------------------------------
To compute average time it takes to protect bitcodes by OH+SROH and SC run ```measure-runtime.sh``` script which will run protection and also generate additional information for the time. Running ```measure-runtime.py``` will generate a table ```runtimes.tex``` in tex directory representing protection runtime data for the dataset programs. It also contains table for with mean, median and standard deviation for protection times. 

Run the whole experiment and dump data by executing:
sh run-all.sh




